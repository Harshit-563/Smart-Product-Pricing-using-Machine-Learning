{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13e59225",
   "metadata": {},
   "source": [
    "# üì¶ Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b064cd58-55f4-48ec-af4e-abd2301e13f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9cb4e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import string\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import lightgbm as lgb\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b918f1c",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Utility Function and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aebca079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (75000, 4)\n",
      "test  (75000, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Symmetric mean absolute percentage error in percent.\"\"\"\n",
    "    y_true = np.array(y_true, dtype=float)\n",
    "    y_pred = np.array(y_pred, dtype=float)\n",
    "    num = np.abs(y_pred - y_true)\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    denom = np.where(denom == 0, 1e-6, denom)\n",
    "    return np.mean(num / denom) * 100.0\n",
    "\n",
    "TRAIN_FILE = Path('train.csv')\n",
    "TEST_FILE = Path('test.csv')\n",
    "\n",
    "train = pd.read_csv(TRAIN_FILE, engine='python', on_bad_lines='warn')\n",
    "test = pd.read_csv(TEST_FILE, engine='python', on_bad_lines='warn')\n",
    "\n",
    "print('train', train.shape)\n",
    "print('test ', test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc656706",
   "metadata": {},
   "source": [
    "# üß† Enhanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd3fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PUNCT_RE = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "NUM_RE = re.compile(r\"(\\d+[\\.,]?\\d*)\")\n",
    "\n",
    "def clean_text(s):\n",
    "    if pd.isna(s):\n",
    "        return ''\n",
    "    s = str(s).lower()\n",
    "    s = s.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "def count_numbers(s):\n",
    "    return len(NUM_RE.findall(s or ''))\n",
    "\n",
    "def extract_numbers(s):\n",
    "    if not s:\n",
    "        return []\n",
    "    return [float(x.replace(',', '')) for x in NUM_RE.findall(str(s))]\n",
    "\n",
    "def extract_units(s):\n",
    "    if not s:\n",
    "        return {}\n",
    "    s = str(s).lower()\n",
    "    units = {\n",
    "        'oz': len(re.findall(r'\\b\\d+[\\.\\d]*\\s*oz\\b', s)),\n",
    "        'lb': len(re.findall(r'\\b\\d+[\\.\\d]*\\s*lb\\b', s)),\n",
    "        'g': len(re.findall(r'\\b\\d+[\\.\\d]*\\s*g\\b', s)),\n",
    "        'kg': len(re.findall(r'\\b\\d+[\\.\\d]*\\s*kg\\b', s)),\n",
    "        'ml': len(re.findall(r'\\b\\d+[\\.\\d]*\\s*ml\\b', s)),\n",
    "        'l': len(re.findall(r'\\b\\d+[\\.\\d]*\\s*l\\b', s)),\n",
    "        'count': len(re.findall(r'\\b\\d+[\\.\\d]*\\s*count\\b', s)),\n",
    "        'pack': len(re.findall(r'pack\\s*of\\s*\\d+|\\d+\\s*pack', s))\n",
    "    }\n",
    "    return units\n",
    "\n",
    "def extract_value_unit(s):\n",
    "    if not s:\n",
    "        return -1, 'unknown'\n",
    "    value_match = re.search(r'value:\\s*(\\d+[\\.\\d]*)', str(s).lower())\n",
    "    unit_match = re.search(r'unit:\\s*(\\w+)', str(s).lower())\n",
    "    value = float(value_match.group(1)) if value_match else -1\n",
    "    unit = unit_match.group(1) if unit_match else 'unknown'\n",
    "    return value, unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a10bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train['catalog_clean'] = train['catalog_content'].fillna('').map(clean_text)\n",
    "test['catalog_clean'] = test['catalog_content'].fillna('').map(clean_text)\n",
    "\n",
    "train['text_len'] = train['catalog_clean'].str.len().fillna(0)\n",
    "train['word_count'] = train['catalog_clean'].str.split().map(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "train['num_count'] = train['catalog_clean'].map(count_numbers)\n",
    "\n",
    "test['text_len'] = test['catalog_clean'].str.len().fillna(0)\n",
    "test['word_count'] = test['catalog_clean'].str.split().map(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "test['num_count'] = test['catalog_clean'].map(count_numbers)\n",
    "\n",
    "def extract_numeric_features(df):\n",
    "    all_nums = df['catalog_clean'].map(extract_numbers)\n",
    "    df['num_max'] = all_nums.map(lambda x: max(x) if x else -1)\n",
    "    df['num_min'] = all_nums.map(lambda x: min(x) if x else -1)\n",
    "    df['num_mean'] = all_nums.map(lambda x: np.mean(x) if x else -1)\n",
    "    df['num_sum'] = all_nums.map(lambda x: sum(x) if x else -1)\n",
    "\n",
    "    units_data = df['catalog_clean'].map(extract_units)\n",
    "    for unit in ['oz', 'lb', 'g', 'kg', 'ml', 'l', 'count', 'pack']:\n",
    "        df[f'has_{unit}'] = units_data.map(lambda x: x.get(unit, 0))\n",
    "\n",
    "    value_unit = df['catalog_clean'].map(extract_value_unit)\n",
    "    df['product_value'] = value_unit.map(lambda x: x[0])\n",
    "    df['product_unit'] = value_unit.map(lambda x: x[1])\n",
    "    return df\n",
    "\n",
    "train = extract_numeric_features(train)\n",
    "test = extract_numeric_features(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07116c43",
   "metadata": {},
   "source": [
    "# üè∑Ô∏è Additional Features (IPQ, Brand, Units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a6c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IPQ_PATTERNS = [\n",
    "    r\"pack of\\s*(\\d+)\",\n",
    "    r\"\\b(\\d+)\\s*pack\\b\",\n",
    "    r\"\\b(\\d+)\\s*pcs?\\b\",\n",
    "    r\"\\b(\\d+)\\s*count\\b\",\n",
    "    r\"\\b(\\d+)[\\\\s-]?ml\\b\",\n",
    "    r\"\\b(\\d+)[\\\\s-]?g\\b\",\n",
    "    r\"\\b(\\d+)\\s*x\\b\",\n",
    "    r\"\\((\\d+)\\)\",\n",
    "]\n",
    "\n",
    "def extract_ipq_val(s):\n",
    "    if not s:\n",
    "        return -1\n",
    "    s = str(s)\n",
    "    for pat in IPQ_PATTERNS:\n",
    "        m = re.search(pat, s)\n",
    "        if m:\n",
    "            try:\n",
    "                return int(m.group(1))\n",
    "            except:\n",
    "                continue\n",
    "    return -1\n",
    "\n",
    "train['ipq'] = train['catalog_clean'].map(extract_ipq_val)\n",
    "test['ipq'] = test['catalog_clean'].map(extract_ipq_val)\n",
    "\n",
    "def guess_brand(s):\n",
    "    if not s:\n",
    "        return 'unknown'\n",
    "    s0 = s.split(' - ')[0]\n",
    "    s0 = s0.split(':')[0]\n",
    "    s0 = s0.split('|')[0]\n",
    "    m = re.search(r\"by\\s+([a-z0-9\\-\\&]+)\", s0)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    tok = s0.split()[0] if s0.split() else 'unknown'\n",
    "    return tok\n",
    "\n",
    "train['brand_guess'] = train['catalog_clean'].map(guess_brand)\n",
    "test['brand_guess'] = test['catalog_clean'].map(guess_brand)\n",
    "\n",
    "brand_counts = train['brand_guess'].value_counts().to_dict()\n",
    "train['brand_freq'] = train['brand_guess'].map(lambda x: brand_counts.get(x, 0))\n",
    "test['brand_freq'] = test['brand_guess'].map(lambda x: brand_counts.get(x, 0))\n",
    "\n",
    "unit_counts = train['product_unit'].value_counts().to_dict()\n",
    "train['unit_freq'] = train['product_unit'].map(lambda x: unit_counts.get(x, 0))\n",
    "test['unit_freq'] = test['product_unit'].map(lambda x: unit_counts.get(x, 0))\n",
    "\n",
    "train['price_per_word'] = train['price'] / (train['word_count'] + 1)\n",
    "train['price_per_num'] = train['price'] / (train['num_count'] + 1)\n",
    "\n",
    "test['price_per_word'] = -1\n",
    "test['price_per_num'] = -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67ef9b",
   "metadata": {},
   "source": [
    "# üî† TF-IDF and SVD Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0457717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TF-IDF features...\n",
      "Applying SVD...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Creating TF-IDF features...\")\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    max_features=50000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=1,\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    analyzer='char',\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=2,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_word_train = word_vectorizer.fit_transform(train['catalog_clean'].fillna(''))\n",
    "X_word_test = word_vectorizer.transform(test['catalog_clean'].fillna(''))\n",
    "\n",
    "X_char_train = char_vectorizer.fit_transform(train['catalog_clean'].fillna(''))\n",
    "X_char_test = char_vectorizer.transform(test['catalog_clean'].fillna(''))\n",
    "\n",
    "print(\"Applying SVD...\")\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_svd_train = svd.fit_transform(X_word_train)\n",
    "X_svd_test = svd.transform(X_word_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45faccad",
   "metadata": {},
   "source": [
    "# üß© Combine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c87ecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (75000, 70069)\n",
      "X_test shape: (75000, 70069)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_features = [\n",
    "    'text_len', 'word_count', 'num_count', 'ipq', 'brand_freq',\n",
    "    'num_max', 'num_min', 'num_mean', 'num_sum',\n",
    "    'has_oz', 'has_lb', 'has_g', 'has_kg', 'has_ml', 'has_l', 'has_count', 'has_pack',\n",
    "    'product_value', 'unit_freq'\n",
    "]\n",
    "\n",
    "X_num_train = train[num_features].fillna(-1).values\n",
    "X_num_test = test[num_features].fillna(-1).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_num_train = scaler.fit_transform(X_num_train)\n",
    "X_num_test = scaler.transform(X_num_test)\n",
    "\n",
    "X_train = sparse.hstack([\n",
    "    X_word_train,\n",
    "    X_char_train,\n",
    "    sparse.csr_matrix(X_svd_train),\n",
    "    sparse.csr_matrix(X_num_train)\n",
    "]).tocsr()\n",
    "\n",
    "X_test = sparse.hstack([\n",
    "    X_word_test,\n",
    "    X_char_test,\n",
    "    sparse.csr_matrix(X_svd_test),\n",
    "    sparse.csr_matrix(X_num_test)\n",
    "]).tocsr()\n",
    "\n",
    "y = np.log1p(train['price'].values)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75e723",
   "metadata": {},
   "source": [
    "# üöÄ LightGBM Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f2b741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting cross-validation...\n",
      "\n",
      "==================================================\n",
      "Fold 1/5\n",
      "==================================================\n",
      "[200]\ttrain's rmse: 0.654866\tvalid's rmse: 0.720837\n",
      "[400]\ttrain's rmse: 0.613359\tvalid's rmse: 0.703382\n",
      "[600]\ttrain's rmse: 0.586309\tvalid's rmse: 0.694516\n",
      "[800]\ttrain's rmse: 0.564076\tvalid's rmse: 0.689256\n",
      "[1000]\ttrain's rmse: 0.547071\tvalid's rmse: 0.685004\n",
      "[1200]\ttrain's rmse: 0.530883\tvalid's rmse: 0.681949\n",
      "[1400]\ttrain's rmse: 0.515839\tvalid's rmse: 0.679292\n",
      "[1600]\ttrain's rmse: 0.50316\tvalid's rmse: 0.677697\n",
      "[1800]\ttrain's rmse: 0.491209\tvalid's rmse: 0.676065\n",
      "[2000]\ttrain's rmse: 0.479708\tvalid's rmse: 0.674702\n",
      "[2200]\ttrain's rmse: 0.46848\tvalid's rmse: 0.673308\n",
      "[2400]\ttrain's rmse: 0.45795\tvalid's rmse: 0.672301\n",
      "[2600]\ttrain's rmse: 0.448197\tvalid's rmse: 0.671604\n",
      "[2800]\ttrain's rmse: 0.438236\tvalid's rmse: 0.671069\n",
      "[3000]\ttrain's rmse: 0.429111\tvalid's rmse: 0.670576\n",
      "[3200]\ttrain's rmse: 0.420858\tvalid's rmse: 0.670223\n",
      "[3400]\ttrain's rmse: 0.411974\tvalid's rmse: 0.669797\n",
      "[3600]\ttrain's rmse: 0.403663\tvalid's rmse: 0.669387\n",
      "[3800]\ttrain's rmse: 0.395768\tvalid's rmse: 0.669215\n",
      "[4000]\ttrain's rmse: 0.387479\tvalid's rmse: 0.669017\n",
      "[4200]\ttrain's rmse: 0.380672\tvalid's rmse: 0.668603\n",
      "[4400]\ttrain's rmse: 0.373519\tvalid's rmse: 0.668124\n",
      "[4600]\ttrain's rmse: 0.366298\tvalid's rmse: 0.667943\n",
      "[4800]\ttrain's rmse: 0.358719\tvalid's rmse: 0.667607\n",
      "[5000]\ttrain's rmse: 0.352483\tvalid's rmse: 0.667471\n",
      "Fold 1 SMAPE: 50.3725\n",
      "\n",
      "==================================================\n",
      "Fold 2/5\n",
      "==================================================\n",
      "[200]\ttrain's rmse: 0.661921\tvalid's rmse: 0.704661\n",
      "[400]\ttrain's rmse: 0.620311\tvalid's rmse: 0.687413\n",
      "[600]\ttrain's rmse: 0.592351\tvalid's rmse: 0.678413\n",
      "[800]\ttrain's rmse: 0.570119\tvalid's rmse: 0.672646\n",
      "[1000]\ttrain's rmse: 0.553199\tvalid's rmse: 0.669115\n",
      "[1200]\ttrain's rmse: 0.537175\tvalid's rmse: 0.66604\n",
      "[1400]\ttrain's rmse: 0.522281\tvalid's rmse: 0.663694\n",
      "[1600]\ttrain's rmse: 0.509245\tvalid's rmse: 0.661748\n",
      "[1800]\ttrain's rmse: 0.496391\tvalid's rmse: 0.660021\n",
      "[2000]\ttrain's rmse: 0.484649\tvalid's rmse: 0.658778\n",
      "[2200]\ttrain's rmse: 0.473238\tvalid's rmse: 0.65744\n",
      "[2400]\ttrain's rmse: 0.462904\tvalid's rmse: 0.656704\n",
      "[2600]\ttrain's rmse: 0.453191\tvalid's rmse: 0.656194\n",
      "[2800]\ttrain's rmse: 0.443954\tvalid's rmse: 0.65571\n",
      "[3000]\ttrain's rmse: 0.43496\tvalid's rmse: 0.655002\n",
      "[3200]\ttrain's rmse: 0.426123\tvalid's rmse: 0.654724\n",
      "[3400]\ttrain's rmse: 0.417637\tvalid's rmse: 0.654397\n",
      "[3600]\ttrain's rmse: 0.409224\tvalid's rmse: 0.654044\n",
      "[3800]\ttrain's rmse: 0.400916\tvalid's rmse: 0.653797\n",
      "[4000]\ttrain's rmse: 0.39305\tvalid's rmse: 0.653549\n",
      "[4200]\ttrain's rmse: 0.385338\tvalid's rmse: 0.653282\n",
      "[4400]\ttrain's rmse: 0.377539\tvalid's rmse: 0.653187\n",
      "Fold 2 SMAPE: 49.4516\n",
      "\n",
      "==================================================\n",
      "Fold 3/5\n",
      "==================================================\n",
      "[200]\ttrain's rmse: 0.662582\tvalid's rmse: 0.705015\n",
      "[400]\ttrain's rmse: 0.618554\tvalid's rmse: 0.68688\n",
      "[600]\ttrain's rmse: 0.591254\tvalid's rmse: 0.677975\n",
      "[800]\ttrain's rmse: 0.569238\tvalid's rmse: 0.67216\n",
      "[1000]\ttrain's rmse: 0.550251\tvalid's rmse: 0.668192\n",
      "[1200]\ttrain's rmse: 0.53451\tvalid's rmse: 0.665493\n",
      "[1400]\ttrain's rmse: 0.518876\tvalid's rmse: 0.662982\n",
      "[1600]\ttrain's rmse: 0.505098\tvalid's rmse: 0.661362\n",
      "[1800]\ttrain's rmse: 0.492601\tvalid's rmse: 0.659914\n",
      "[2000]\ttrain's rmse: 0.480712\tvalid's rmse: 0.658735\n",
      "[2200]\ttrain's rmse: 0.468448\tvalid's rmse: 0.657657\n",
      "[2400]\ttrain's rmse: 0.456968\tvalid's rmse: 0.656362\n",
      "[2600]\ttrain's rmse: 0.446663\tvalid's rmse: 0.6556\n",
      "[2800]\ttrain's rmse: 0.437263\tvalid's rmse: 0.654714\n",
      "[3000]\ttrain's rmse: 0.428931\tvalid's rmse: 0.654195\n",
      "[3200]\ttrain's rmse: 0.420173\tvalid's rmse: 0.653772\n",
      "[3400]\ttrain's rmse: 0.41208\tvalid's rmse: 0.653495\n",
      "[3600]\ttrain's rmse: 0.404246\tvalid's rmse: 0.652945\n",
      "[3800]\ttrain's rmse: 0.395783\tvalid's rmse: 0.652426\n",
      "[4000]\ttrain's rmse: 0.387824\tvalid's rmse: 0.652194\n",
      "[4200]\ttrain's rmse: 0.380411\tvalid's rmse: 0.651907\n",
      "[4400]\ttrain's rmse: 0.373542\tvalid's rmse: 0.651655\n",
      "[4600]\ttrain's rmse: 0.3668\tvalid's rmse: 0.651451\n",
      "[4800]\ttrain's rmse: 0.35933\tvalid's rmse: 0.651125\n",
      "[5000]\ttrain's rmse: 0.352468\tvalid's rmse: 0.650943\n",
      "Fold 3 SMAPE: 49.7044\n",
      "\n",
      "==================================================\n",
      "Fold 4/5\n",
      "==================================================\n",
      "[200]\ttrain's rmse: 0.664037\tvalid's rmse: 0.691462\n",
      "[400]\ttrain's rmse: 0.621127\tvalid's rmse: 0.673824\n",
      "[600]\ttrain's rmse: 0.593377\tvalid's rmse: 0.665747\n",
      "[800]\ttrain's rmse: 0.571798\tvalid's rmse: 0.660728\n",
      "[1000]\ttrain's rmse: 0.552655\tvalid's rmse: 0.656981\n",
      "[1200]\ttrain's rmse: 0.53696\tvalid's rmse: 0.654742\n",
      "[1400]\ttrain's rmse: 0.521814\tvalid's rmse: 0.652472\n",
      "[1600]\ttrain's rmse: 0.507879\tvalid's rmse: 0.650788\n",
      "[1800]\ttrain's rmse: 0.49514\tvalid's rmse: 0.649544\n",
      "[2000]\ttrain's rmse: 0.482725\tvalid's rmse: 0.648411\n",
      "[2200]\ttrain's rmse: 0.471234\tvalid's rmse: 0.647597\n",
      "[2400]\ttrain's rmse: 0.460242\tvalid's rmse: 0.64687\n",
      "[2600]\ttrain's rmse: 0.450315\tvalid's rmse: 0.646085\n",
      "[2800]\ttrain's rmse: 0.440507\tvalid's rmse: 0.645749\n",
      "[3000]\ttrain's rmse: 0.430499\tvalid's rmse: 0.645354\n",
      "[3200]\ttrain's rmse: 0.421625\tvalid's rmse: 0.645096\n",
      "[3400]\ttrain's rmse: 0.41251\tvalid's rmse: 0.645081\n",
      "[3600]\ttrain's rmse: 0.403272\tvalid's rmse: 0.644173\n",
      "[3800]\ttrain's rmse: 0.395464\tvalid's rmse: 0.644007\n",
      "[4000]\ttrain's rmse: 0.387909\tvalid's rmse: 0.643842\n",
      "[4200]\ttrain's rmse: 0.380172\tvalid's rmse: 0.643693\n",
      "[4400]\ttrain's rmse: 0.373071\tvalid's rmse: 0.643685\n",
      "Fold 4 SMAPE: 48.9338\n",
      "\n",
      "==================================================\n",
      "Fold 5/5\n",
      "==================================================\n",
      "[200]\ttrain's rmse: 0.657731\tvalid's rmse: 0.708452\n",
      "[400]\ttrain's rmse: 0.615258\tvalid's rmse: 0.692195\n",
      "[600]\ttrain's rmse: 0.587236\tvalid's rmse: 0.68383\n",
      "[800]\ttrain's rmse: 0.566169\tvalid's rmse: 0.678862\n",
      "[1000]\ttrain's rmse: 0.549288\tvalid's rmse: 0.675759\n",
      "[1200]\ttrain's rmse: 0.532275\tvalid's rmse: 0.673001\n",
      "[1400]\ttrain's rmse: 0.518124\tvalid's rmse: 0.671131\n",
      "[1600]\ttrain's rmse: 0.503288\tvalid's rmse: 0.669119\n",
      "[1800]\ttrain's rmse: 0.49033\tvalid's rmse: 0.667732\n",
      "[2000]\ttrain's rmse: 0.478758\tvalid's rmse: 0.66657\n",
      "[2200]\ttrain's rmse: 0.466746\tvalid's rmse: 0.665709\n",
      "[2400]\ttrain's rmse: 0.455759\tvalid's rmse: 0.66469\n",
      "[2600]\ttrain's rmse: 0.445576\tvalid's rmse: 0.664248\n",
      "[2800]\ttrain's rmse: 0.436034\tvalid's rmse: 0.663882\n",
      "[3000]\ttrain's rmse: 0.426194\tvalid's rmse: 0.663424\n",
      "[3200]\ttrain's rmse: 0.417126\tvalid's rmse: 0.663182\n",
      "[3400]\ttrain's rmse: 0.408353\tvalid's rmse: 0.663002\n",
      "[3600]\ttrain's rmse: 0.400395\tvalid's rmse: 0.662788\n",
      "[3800]\ttrain's rmse: 0.39285\tvalid's rmse: 0.662515\n",
      "[4000]\ttrain's rmse: 0.384929\tvalid's rmse: 0.662021\n",
      "[4200]\ttrain's rmse: 0.377873\tvalid's rmse: 0.661967\n",
      "Fold 5 SMAPE: 49.8977\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgb_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.03,\n",
    "    'num_leaves': 63,\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 30,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 0.5,\n",
    "    'min_gain_to_split': 0.01,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'force_row_wise': True\n",
    "}\n",
    "\n",
    "NFOLD = 5\n",
    "kf = KFold(n_splits=NFOLD, shuffle=True, random_state=42)\n",
    "\n",
    "preds_oof = np.zeros(len(train))\n",
    "preds_test = np.zeros(len(test))\n",
    "\n",
    "print(\"\\nStarting cross-validation...\")\n",
    "for fold, (tr_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "    print(f'\\n{\"=\"*50}')\n",
    "    print(f'Fold {fold+1}/{NFOLD}')\n",
    "    print(f'{\"=\"*50}')\n",
    "    \n",
    "    X_tr = X_train[tr_idx]\n",
    "    X_val = X_train[val_idx]\n",
    "    y_tr = y[tr_idx]\n",
    "    y_val = y[val_idx]\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_tr, label=y_tr)\n",
    "    dval = lgb.Dataset(X_val, label=y_val, reference=dtrain)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        lgb_params,\n",
    "        dtrain,\n",
    "        num_boost_round=5000,\n",
    "        valid_sets=[dtrain, dval],\n",
    "        valid_names=['train', 'valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=150, verbose=False),\n",
    "            lgb.log_evaluation(period=200)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preds_oof[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    preds_test += model.predict(X_test, num_iteration=model.best_iteration) / NFOLD\n",
    "    \n",
    "    fold_smape = smape(np.expm1(y_val), np.expm1(preds_oof[val_idx]))\n",
    "    print(f'Fold {fold+1} SMAPE: {fold_smape:.4f}')\n",
    "    \n",
    "    joblib.dump(model, f'lgb_enhanced_fold{fold+1}.pkl')\n",
    "    \n",
    "    del dtrain, dval, X_tr, X_val, y_tr, y_val\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b11f697",
   "metadata": {},
   "source": [
    "# üìä Evaluation and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "527810f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Enhanced Model CV SMAPE: 49.6720\n",
      "==================================================\n",
      "\n",
      "Saved test_out_enhanced.csv\n",
      "Saved train_oof_enhanced.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_pred_price = np.expm1(preds_oof)\n",
    "cv_smape = smape(train['price'].values, train_pred_price)\n",
    "print(f'\\n{\"=\"*50}')\n",
    "print(f'Enhanced Model CV SMAPE: {cv_smape:.4f}')\n",
    "print(f'{\"=\"*50}')\n",
    "\n",
    "test_pred_price = np.clip(np.expm1(preds_test), 0.01, None)\n",
    "submission = pd.DataFrame({\n",
    "    'sample_id': test['sample_id'],\n",
    "    'price': test_pred_price\n",
    "})\n",
    "submission.to_csv('test_out_enhanced.csv', index=False)\n",
    "print('\\nSaved test_out_enhanced.csv')\n",
    "\n",
    "train_oof = pd.DataFrame({\n",
    "    'sample_id': train['sample_id'],\n",
    "    'price': train['price'],\n",
    "    'pred_price': train_pred_price\n",
    "})\n",
    "train_oof.to_csv('train_oof_enhanced.csv', index=False)\n",
    "print('Saved train_oof_enhanced.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb021b-bb6e-4944-8fe4-61125a937c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
